[[!meta title="Automated tests using cucumber"]]

[[!toc levels=2]]

About this
==========

The automated test suite is being implemented in the
`feature/automated_tests/cucumber` branch.

* Documentation: `contribute/release_process/test/automated_tests.mdwn`
* Setup: `contribute/release_process/test/setup.mdwn`
* Usage: `contribute/release_process/test.mdwn`


TODO and issues
===============

## Merge this branch

1. Split non-blockers into separate tickets.
1. Merge this branch.

## Tests from our manual test suite not yet covered

See [[contribute/release_process/test]] for progress.

## Puppet module to manage the tester system

The [[contribute/release_process/test/setup]] documentation should be
turned into a Puppet
module, so that we can deploy this on lizard (and so that individual
developers can reproduce this setup in a way that's easy to keep
up-to-date with future changes).

## sdmem job waiting vs erase_memory feature

When we'll merge `feature/automated_tests/cucumber` into `stable` we'll
revert commit `255aa71` ("Make sure the memory dumping debug message
is shown cleanly") to not mess anything up for the imminent 0.17.2
release at the time. However, the `erase_memory` feature depends on
it, so we must remember to consider reverting that revert after the
release: we should first determine whether `255aa71` is safe or even
the right approach.

## Kernel Oops on real host for erase_memory feature in nested VM setup

The top excerpt of the kernel oops (which leaves the real host
completely unresponsive) is:

    BUG: unable to handle kernel paging request at ffff87ffffffffff
    IP: [<ffffffffa06ea57a>] __direct_map.isra.92+0xe3/0x1a1 [kvm]
    PDF 0
    Oops: 0000 [#1] SMP
    Modules: [snip]
    CPU 2
    Pid: 5229, comm: kvm Not tainted 3.8-trunk-amd64 #1 Debian 3.8.3-1~experimental.1 [snip]
	[snip]

It has happened every time I tried this feature, either when filling
the memory or when wiping it. I've tested all combinations of the
current Wheezy kernel (3.2.39-2) and current experimental kernel
(3.8.3-1) on both the real host and the testing VM, but to no avail.

I don't get this with a non-nested VM setup (i.e. when the automated
test suite is run from bare metal).

Also, I don't get it *as often* in the nested VM setup if I decrease
the TailsToaster RAM from 8 GiB to 5 GiB in both scenarios.

So it seems we may have an upstream linux kernel bug. Can someone else
than me (anonym) try to verify this?

## Get rid of RVM and ruby gems

Ultimately we want good enough versions of JRuby and the required ruby
gems properly packaged in Debian. Filing RFP bugs, to let people know
what we need, would be a good start.

Alternatively we drop JRuby and use native Ruby, which means we can
use the Ruby gems already packaged for Debian, which include all but
`sikuli` (which we cannot use without JRuby, so we need another
solution; see below) and `packetfu`, so in effect only the latter
needs an RFP bug, with this approach.

We need serious plans to make this solution sustainable for us.

## jruby 1.7 has deprecated the C extension

This is bad news as some of the ruby gems we use depend on it:

* `ruby-libvirt` (highly critical)
* `system_timer` (not critical)

It currently means that we're stuck using `jruby 1.6.x`, which isn't
so bad in the short run, but we need a contingency plan.

> Perhaps we can allow ourselves to be stuck with 1.6.x for Wheezy
> iff. we do whatever is needed so that we can do better for Jessie,
> considering a newer OS will probably bring incompatibilities with
> "old" software.
>
> Actually, this may be needed quite soon: our current tester system
> setup needs a libvirt/qemu stack that is only available in unstable
> and experimental; we'll be unable to install new versions of these
> packages on Wheezy soon after the Jessie development cycle starts,
> so it's likely that we soon have to manage a testing environment
> based on Jessie... or maintain tons of backports.

The best would probably be if we could move to native ruby, which
would mean porting the sikuli gem somehow. Since many of our gems are
in Debian for native ruby, we'd mostly solve "Get rid of RVM and ruby
gems" at the same time.

### Rjb

[[rjb|<http://rjb.rubyforge.org/>]] seems maintained, if not actively developed.

Other projects using it or interesting stuff at:

* [rjb-require](https://github.com/svenfuchs/rjb-require)
* [rjb-examples](https://github.com/L2G/rjb-example)
* [poi_pond](https://github.com/lgleasain/poi_pond) (uses Rjb)
* [Antrap](https://github.com/atoulme/Antwrap) (uses rjb)

The jruby sikuli gem is quite simple, implementing it in Rjb can be as
lightweight, or not...

### Wrapping Sikuli commands via a stand-alone Sikuli server

If the Rjb solution doesn't work out, this fallback is a drop-in
replacement for the Sikuli gem, and that we know will work no matter
what, and that should be reasonably easy to implement.

In short, we create a pure Java program that controls a single
`Screen` object, and listens for commands that that it translates into
Sikuli API calls for that `Screen` object, and then responds
appropriately to the calling client.

#### Details

1. We write a pure Java program using the Java API for Sikuli, that
   takes the `$DISPLAY`, image dir etc. as arguments and then sets up
   all required Sikuli objects: Mouse and Keyboard robots, and a single
   `Screen` object. Let's call this the "Sikuli server".

1. The Sikuli server listens (on a UNIX socket, or whatever) for
   "Sikuli commands" that it translates to Sikuli calls on the single
   `Screen` object via the Sikuli API, and then translates the result
   and sends that as a response.

1. We completely re-write `sikuli_helper.rb`, defining a `Screen`
   class (and possibly `Region`; see below). On `initialize()` it
   starts a Sikuli server instance (simply via `Popen()` or whatever).
   We implement simple wrappers for all methods we've used earlier
   (i.e. `find()`, `wait()`, `type()`, `hover()` and `click()`) that
   will send an appropriate command to the Sikuli server.

#### Example

Say `screen` is an instance of `sikuli_helper.rb`'s `Screen`. Then
`screen.wait("image.png", 100)` will result in something like
`wait,image.png,100` being sent to the Sikuli server, which it
translates into the call `screenObject.wait("image.png", 100)`, and
responds back with something easily parsable, like
`exception=ImageNotFound:Could not find image.png` (or whatever the
exact exception name and message are) on failure, otherwise it just
sends an ACK so `screen.wait()` can stop blocking execution.

> I'd rather not invent a new protocol entirely, and instead
> piggy-back e.g. on HTTP or something more appropriate. Also, I'd
> rather use a well-known, well-defined serialization format (YAML,
> JSON, you name it) instead of inventing a new one.

#### Obstacles

* There may be some complexity to deal with `Region` objects (returned
  by e.g. `find()`, which we use in `wait_and_click()`) since we'd
  need some way (an identifier?) to know which `Region` object in
  `sikuli_helper.rb` corresponds to which `Region` (Java) object in
  the Sikuli server; we avoid this issue with `Screen` since each
  Sikuli server deals with a single `Screen` object, but we can
  potentially deal with any number of `Region` objects. A simple
  solution would be to only store the appropriate coordinates and
  dimensions in `sikuli_helper.rb`'s `Region` object and then whenever
  it's used we create a new `Region` object in the Sikuli server using
  those coordinates and dimensions. We could then implement methods
  via the `Screen` object, like `Region.click()` could use those
  coordinates and dimensions to `Screen.click()` on the right place.
  We currently only use `Region` in our `wait_and_click` helper, so
  a ad-hoc solution would probably be enough.

* Getting Sikuli's key constants (e.g. `Sikuli::KEY_CTRL`) into
  `sikuli_helper.rb` is not completely trivial. Perhaps we could make
  the Sikuli server send the values of all these so they can be stored
  into the appropriate constants upon `Screen.initialize()`, when the
  server is first contacted? Otherwise we can always statically define
  them with magic values.

### Plan for dropping JRuby and the Sikuli gem

1. bertagaz investigates (hopefully done in early-mid April 2013)
   whether a native ruby port of the Sikuli gem (using Rjb or other
   means) is possible *and* easy.

2. If not, anonym will implement the Sikuli wrapper server during the
   summer 2013.

## Use libguestfs

Currently we use an ad-hoc `dd`/`parted` combo in the storage helper
to create disk images with formatted filesystems outside of Tails to
later be used within Tails (e.g. for the untrusted partitions
feature). This limits us in many ways:

* the disk can only be backed by a `raw` image, which consumes its
  full capacity in disk space on the host unlike e.g. `qcow2` images.
* we can only create filesystems supported by `parted` which are
  very limited in number.
* acting directly on the block device (= image) if we want to use
  `LVM` or `LUKS` will probably get complicated permission-wise as the
  test suite runs as an unprivileged user. It gets impossible if we'd
  use image types other than `raw` (unless something like `qemu-nbd`
  is used to create virtual block devices of the images, which again
  will require privileges).

At other places (e.g. the USB install feature) we use `udisks` from
inside Tails to query disk information, but this should preferably be
made from the "outside" (i.e. no inside Tails, which is what we test).

[libguestfs](http://libguestfs.org/) supports all of the above and is
part of the libvirt "family" of tools (and deal with permissions in
the same, sane way), and it has ruby bindings. It seems like a perfect
fit.

## Remove race condition-prone sleep():s

A `sleep` that's good enough on your hardware might not be good enough
on mine. We need to, whenever possible, use reliable ways to detect
the state we are waiting for instead of `sleep`:ing some fixed time
and hoping we've reached that state by then.

## Retry when Tor fails

Some scenarios uses the live Tor network, which is not entirely
reliable, so we may get failing scenarios when in fact we just
happened to pick a Tor circuit that's too slow, or even one that's
broken but Tor fails to remedy the situation. For this reason we may
want to tag such scenarios with `@uses_tor`, and create an
`Around('@uses_tor')` hook which re-tries those scenarios some number
of times before actually failing it.

## Fetch Tor authorities from somewhere?

In `features/support/config.rb` we have a static list of the IP
addresses of the Tor authorities. It'd be great if we could fetch it
dynamically, but with up-to-date info, and with authentication.

## Background snapshots

While these are invaluable for speeding up the test suite and not
hammering the Tor authorities excessively with complete bootstraps,
they do introduce some ugly code overhead and confusion:

* There's the need of the "I save the state ..." step at the end of
  the Background, which is pretty hackish.
* Each "skippable" step needs an `next if ...` line around the top of
  the step.
* In the previous point I say "around" the top, because sometimes
  input from a step are to be saved in some global variable to be
  accessible for subsequent steps, and then those assignments should
  happen before the `next if ...`. It's pretty confusing.

It'd be great if we could tag steps `@skippable` and skip them when
appropriate using something like an `AroundStep('@skippable')` hook,
but vanilla cucumber supports neither tagging of steps not such a hook
([cucumber-cpp](https://www.ohloh.net/p/cucumber-cpp/) does,
though). OTOH, with all that we'd be unable to save any input from the
skipped steps, which probably would require some interesting
workarounds (maybe using real `$global` variables instead of `@class`
variables will do?).

So the question is if we really can improve the situation. An
`AfterBackground` hook would at least be nice for killing the "I save
the state ..." step.

## Media removal doesn't register (for udev) in guest

While it's possible to tell libvirt to forcefully remove both DVD and USB
media, it doesn't result in the signal (or whatever) that our udev watchdog
wants being emited. The media just gets inaccessible with lots of IO errors
going on. This prevents implementation of the tests:

* erase memory on shutdown
  - After booting from DVD, remove Tails boot medium and check that
    the memory erasure process is started (`Loading new kernel`, at
    least).  The USB tests are bellow, in the USB installer section.

* USB Installer/Upgrader
  - The installed or upgraded Tails medium shall have the "emergency
    shutdown on boot medium removal" feature working: remove Tails
    boot medium and check that the memory erasure process is started
    (`Loading new kernel`, at least).

## Remote shell

### pgrep -f detects itself

When running `@vm.execute("pgrep -f $something")` it currently the
case that `pgrep` lists its own pid (and hence never fails, which
could be of great importance), unlike when you run it natively, and
unlike "The running pgrep or pkill process will never report itself as
a match." in `pgrep(1)`.

The practical problem is the (potentially serious) surprise one can be
hit by when writing a step definition.

Why is that happening? Are other tools misbehaving?

## usb_install feature

This feature seems to require a fast setup to work. Other than that it often
fails in quite random fashion (frozen in the 'unmouting /dev/sda'
liveusb-creator step for example).

It could be considered stable and useable only on fast setup.

### Shutdown Tails step

Is actually a bit error prone. As this feature has to run on fast VM, this
step often fails if the Tails VM has more memory than the default, as the VM
takes long time to do the memory wiping on shutdown (perticulary in nested VM
setup).

> Indeed. Let's bump the timeout into "5 minutes per GiB or RAM", like
> when we wait for the memory to be wiped in in erase_memory.feature.
> See commit 0867398.

This `Shutdown Tails` step seems to be used only in this feature and the
memory wiping one. Maybe we could have 2 different ways to shutdown the
machine, and in the case of this feature, simply use a `@vm.destroy`.

> erase_memory.feature uses "I safely shutdown Tails" (which is a bad
> name) which doesn't wait for the VM to shutdown, like "I shutdown
> Tails" does. In that feature we instead wait for the wipe to finish
> so we can dump the memory.

> In this feature we cannot use `@vm.destroy` since that can result in
> data loss from the USB drive (perhaps not for after installing or
> upgrading since the installer syncs, but certainly when read-write
> persistence is used).

### Upgrade should be from an older Tails

Currently we upgrade Tails from the same version, which isn't what's
said in the manual test suite.

We could save an installed USB disk image at some point (in a step or by a
jenkins trick?), and have it stored somewhere accessible to the test suite so
that it's used in the tests of the next version of Tails. Should be accessible
also for people willing to test this feature.

> I think this would be hard to implement in a not-too-fragile way,
> so I'd rather simply add a `--old-iso` option to `run_test_suite`.

Alternatively we can add an `--old-iso` option to `run_test_suite`,
which, if omitted, defaults to the .iso with oldest mtime. If the
current and "old" ISO images are the same (and perhaps if the time
diff is too small?), we get a warning (or a fatal error?). Actually,
since mtime is not really reliable, I plan to extract the image
creation date via:

    /sbin/blkid -p -s LABEL -o value /path/to/iso

### Disabled scenario: "the boot device has safe access rights"

It turns out our fix for Debian bug #645466 (see
`config/chroot_local_includes/lib/live/config/998-permissions` and the
bug: [[bugs/writable_system_disk:_belongs_to_floppy_group]] (now
reopened)) is not working any more. the boot device (including boot
partition and any persistent partition) is owned by group `floppy`
which the `amnesia` user is a member of, enabling it full write
permissions to it. Is udev doing this at a later stage now?

### liveusb-creator hangs

For me (anonym) `liveusb-creator` constantly hangs at "Unmounting
/dev/sda" when using the nested setup (not otherwise). If I take over
the session with `virt-viewer`, close `liveusv-creator` and restart
it, then it works. Also, doing something completely retarted like this
also works:

    ...
    And I create a new 4 GiB USB drive named "A"
    And I plug USB drive "A"
    And I wait 10 seconds
    And I unplug USB drive "A"
    And I wait 10 seconds
    And I plug USB drive "A"
    And I wait 10 seconds
    And I "Clone & Install" Tails to USB drive "A"
    ...

What can be the cause of this?

## Reliably wait for all post Tails Greeter hooks

In the `I log in to a new session` step we should do something which waits
for all Tails Greeter post-hooks to finish so we can rid ourselves of
steps like `Tails Greeter has dealt with the sudo password`.

## GnuPG encryption feature

All scenarios fail for intrigeri: for some reason "encrypt with
passphrase" is selected even in the scenario that's supposed to hit
"k" to select "encrypt with pubkey".

## apt feature

### fails

    Scenario: Install packages using synaptic                              # features/cucumber/apt/apt.feature:29
      When I run "gksu synaptic"                                           # features/cucumber/step_definitions/common_steps.rb:347
      And I enter the sudo password in the PolicyKit prompt                # features/cucumber/step_definitions/common_steps.rb:353
      And I update APT using synaptic                                      # features/cucumber/apt/step_definitions/apt.rb:39
        The image 'SynapticReloadPrompt.png' did not match in this region. (Sikuli::ImageNotFound)
        ./features/cucumber/apt/step_definitions/apt.rb:46:in `(root)':in `/^I update APT using synaptic$/'
        features/cucumber/apt/apt.feature:32:in `And I update APT using synaptic'

> This should be fixed. Can the bug reporter please retry?

>> Perhaps, but it's now broken earlier:

    Scenario: Install packages using Synaptic                              # features/apt.feature:32
    When I run "gksu synaptic"                                           # features/step_definitions/common_steps.rb:355
    And I enter the sudo password in the gksu prompt                     # features/step_definitions/common_steps.rb:361
      The image 'GksuAuthPrompt.png' did not match in this region. (Sikuli::ImageNotFound)
      ./features/step_definitions/common_steps.rb:363:in `(root)':in `/^I enter the sudo password in the gksu prompt$/'
      features/apt.feature:34:in `And I enter the sudo password in the gksu prompt'


### should run synaptic in a more realistic way

Synaptic should be started from the applications menu, or at least we
should make sure it's started in exactly the same way as it is run by
the `.desktop` by extracting that command-line from the `.desktop`
(e.g. on Wheezy, this will be `synaptic-pkexec`).


## "the shipped Tails signing key is not outdated" scenario

Why not test "old w.r.t. the one we fetch from Tails' website", but
what we mainly need to test here (and the reason why this test was
added to begin with) is that the key (nor any of its subkeys) has
not expired, and won't expire any time soon.

## MAT check fails

... presumably due to some race condition that might simply be avoided
if moved to a dedicated feature:

    And I setup a filesystem share containing a sample PDF               # features/cucumber/misc_tests/step_definitions/checks.rb:103
    And I start the computer                                             # features/cucumber/step_definitions/common_steps.rb:120
      Call to virDomainCreateWithFlags failed: Unable to read from monitor: Connection reset by peer (Libvirt::Error)
      ./features/cucumber/support/helpers/vm_helper.rb:359:in `start'
      ./features/cucumber/step_definitions/common_steps.rb:124:in `(root)':in `/^I start the computer$/'
      features/cucumber/misc_tests/checks.feature:44:in `And I start the computer'

## time syncing feature

* After setting the date to something wrong, one should assert the
  date change actually took place, else it makes little sense
  verifying later that our stuff indeed has "fixed" the date:  if we
  don't know for sure that it was broken, we're not really
  verifying anything. This should be implemented at least in
  `step_definitions/time_syncing.rb`.

## check firewall leaks in every scenario

... or at least, in every scenario that involves the Internet?

## add anti-tests

... that is, tests that verify that the test suite would properly
detect failure. Our manual erase memory test procedure is a good
example thereof: it checks that we *can* find the pattern in memory if
we skip the memory wipe step on purpose.

### firewall_meta.feature

* Do we need an anti-test for non-IP packets? Does it even make sense?
  After all, so far we've only cared about leaks to the Internet. What
  non-IP packets can leak to the Internet?

## Remote shell: minor groups not set

If we run `@vm.execute("groups", "amnesia")` it'll only list
membership in the major group, i.e. `amnesia`.

Ideally, as long as we don't use the remote shell to test actions that
a real user could perform, and only use it to check results and
prepare stuff, this should not be a practical problem.

However, we have at least one exception (apt-get update / install)
that uses the remote shell to emulate user action, and it would be
a pain to rewrite using Sikuli, so we'd rather keep this exception.

This was documented in the "how to write tests" documentation,
but could still be worth fixing.

## Remote shell instability

Although very rare, the remote shell can get into a state where it
stops responding, resulting in the test suite waiting for a response
forever. The reason for this has proved hard to determine, but it
seems to basically only happen for the very first interaction with it.

I think it has to do with the fact that its transport is TCP on the
host bridged to a serial device on the guest (see `<serial
type='tcp'>` in Libvirt domain XML format). Perhaps the TCP state vs
the guest's serial port's state gets out-of-sync if the TCP packet
times out before the serial port is up and running?

## Host-to-guest filesystem share incompatibility with snapshots

Filesystem shares cannot (due to QEMU limitations) be added to an
active VM, and cannot (due to QEMU limitations) be active
(i.e. mounted) during a snapshot save. Hence unmounting before save
and remounting after restore them seems like a good idea.

However, the `9p*` modules seem to get into a broken state during a
save + restore (the "tags" used as `mount` source cannot be found), so
unloading before save and reload after restore comes to mind. But
loading `9pnet_virtio` fails after a restore with `probe of virtio2
failed with error -2` (in `dmesg`) and the shares remain unmountable.

This has to be investigated further, and possible upstream bugs
should be reported.
